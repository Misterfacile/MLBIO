{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUuhlEbqRaxH"
   },
   "source": [
    "# ECG classification\n",
    "\n",
    "Laurent Cetinsoy - Datadidacte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "67fFPUeVOAkg"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import librosa\n",
    "import collections\n",
    "import tensorflow as tf\n",
    "\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import entropy\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97sEwfMhRedx"
   },
   "source": [
    "## A first naive model by extracting simple features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxoiKhQxOAkj"
   },
   "source": [
    "Your environment contains variables arr, nsr, and chf which respectively contain 10-second recordings of ECG signals extracted from three datasets on PhysioNet: one from a person suffering from arrhythmia, one from a person with a normal heart rhythm, and another from a person with heart failure.\n",
    "\n",
    "\n",
    "Matplotlib  subplots (or any other library), display these signals on three subfigures (the subplots should be called with the parameter nrows = 3).\n",
    "Can you find any differences between them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NcOvOjBHOAkn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.loadtxt('arr.txt')\n",
    "chf = np.loadtxt('chf.txt')\n",
    "nsr = np.loadtxt('nsr.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGhUVnqOOAkp"
   },
   "source": [
    "We want to extract features from the time series. For that we will use simple statistics.\n",
    "\n",
    "\n",
    "Create a function named calculate_stats_features(x) that calculates some statistical features of a signal x using standard numpy functions: nanpercentile, nanmean, etc.\n",
    "calculate_stats_features will return a list of features in this order:\n",
    "\n",
    "0. Max\n",
    "1. Min\n",
    "2. Mean\n",
    "3. Median\n",
    "4. Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5bL_r7kpOAkr"
   },
   "outputs": [],
   "source": [
    "def calculate_stats_feature(x):    \n",
    "    return [np.nanmax(x), np.nanmin(x), np.nanmean(x), np.nanmedian(x), np.nanvar(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKjvVXp2OAks"
   },
   "source": [
    "\n",
    "\n",
    "Create a function named `calculate_zero_crossing(x)` that calculates the Zero\n",
    "Crossing of a signal x.\n",
    "\n",
    "The zero crossing is defined as the number of times the signal changes sign.\n",
    "For this, you can use the signbit, diff, and nonzero functions from numpy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "3VYWsUzuOAkt"
   },
   "outputs": [],
   "source": [
    "def calculate_zero_crossing(x):\n",
    "    sign_changes = np.signbit(x)\n",
    "    diff_sign = np.diff(sign_changes)\n",
    "    zero_crossings = np.count_nonzero(diff_sign)\n",
    "    return zero_crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1GOwESaOAku"
   },
   "source": [
    "Create a function named **calculate_rms(x)** that returns the Root Mean Square (RMS) of a signal x. We will use the nanmean function instead of the mean function from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "-U7UijZmOAkv"
   },
   "outputs": [],
   "source": [
    "def calculate_rms(x):\n",
    "    return np.sqrt(np.nanmean(np.square(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8k_q79eOAkx"
   },
   "source": [
    "Create a function named calculate_entropy(x) that calculates the Shannon entropy of a signal x using the entropy function from scipy.stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "a8qCOZ0oOAky"
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(x):\n",
    "    values, counts = np.unique(x, return_counts=True)\n",
    "    prob_dist = counts / counts.sum()\n",
    "    entropy_value = entropy(prob_dist, base=2)\n",
    "    \n",
    "    return entropy_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Si5V1s4TOAky"
   },
   "source": [
    "Create a function get_features(x) that combines the features calculated by all previous functions including caculate_stats_features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lsPvzLLyOAkz"
   },
   "outputs": [],
   "source": [
    "def get_features(x):\n",
    "    \n",
    "    stats_features = calculate_stats_feature(x)\n",
    "    stats_features.append(calculate_zero_crossing(x))\n",
    "    stats_features.append(calculate_rms(x))\n",
    "    stats_features.append(calculate_entropy(x))\n",
    "    \n",
    "    return np.array(stats_features)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFsLZU7NOrwj"
   },
   "source": [
    "Load the small ecg dataset\n",
    "Use your fonction get_features create a new dataframe where you have all the feature as X and y as the label.\n",
    "Train a random forest on it after doing a train test split if the dataset is not too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/_09rqyyj0v3g_c9sgq8sp4k40000gn/T/ipykernel_1950/843125960.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('ECG-laurent.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65528</th>\n",
       "      <th>65529</th>\n",
       "      <th>65530</th>\n",
       "      <th>65531</th>\n",
       "      <th>65532</th>\n",
       "      <th>65533</th>\n",
       "      <th>65534</th>\n",
       "      <th>65535</th>\n",
       "      <th>65536</th>\n",
       "      <th>65537</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>213</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.060085</td>\n",
       "      <td>0.001638</td>\n",
       "      <td>-0.014941</td>\n",
       "      <td>-0.018776</td>\n",
       "      <td>-0.110048</td>\n",
       "      <td>-0.160348</td>\n",
       "      <td>-0.196445</td>\n",
       "      <td>-0.287140</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145316</td>\n",
       "      <td>-0.088612</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.066026</td>\n",
       "      <td>0.154291</td>\n",
       "      <td>0.214976</td>\n",
       "      <td>0.227396</td>\n",
       "      <td>0.172451</td>\n",
       "      <td>0.011588</td>\n",
       "      <td>-0.154281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>213</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.467585</td>\n",
       "      <td>-0.650931</td>\n",
       "      <td>-0.595663</td>\n",
       "      <td>-0.627657</td>\n",
       "      <td>-0.552164</td>\n",
       "      <td>-0.532318</td>\n",
       "      <td>-0.500500</td>\n",
       "      <td>-0.486974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273010</td>\n",
       "      <td>0.279927</td>\n",
       "      <td>0.213876</td>\n",
       "      <td>0.137012</td>\n",
       "      <td>0.019218</td>\n",
       "      <td>-0.031818</td>\n",
       "      <td>-0.068809</td>\n",
       "      <td>-0.068333</td>\n",
       "      <td>-0.178109</td>\n",
       "      <td>-0.136239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.155555</td>\n",
       "      <td>-0.229827</td>\n",
       "      <td>-0.207653</td>\n",
       "      <td>-0.210114</td>\n",
       "      <td>-0.191253</td>\n",
       "      <td>-0.184057</td>\n",
       "      <td>-0.152477</td>\n",
       "      <td>-0.171106</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.238173</td>\n",
       "      <td>-1.112138</td>\n",
       "      <td>-0.812259</td>\n",
       "      <td>-0.595419</td>\n",
       "      <td>-0.444057</td>\n",
       "      <td>-0.326833</td>\n",
       "      <td>-0.117486</td>\n",
       "      <td>-0.038309</td>\n",
       "      <td>-0.015658</td>\n",
       "      <td>0.004507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>207</td>\n",
       "      <td>1</td>\n",
       "      <td>0.099644</td>\n",
       "      <td>0.098019</td>\n",
       "      <td>0.089555</td>\n",
       "      <td>0.108130</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>0.083866</td>\n",
       "      <td>0.073525</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.291689</td>\n",
       "      <td>-0.111845</td>\n",
       "      <td>0.180895</td>\n",
       "      <td>0.373213</td>\n",
       "      <td>0.486517</td>\n",
       "      <td>0.394578</td>\n",
       "      <td>0.283331</td>\n",
       "      <td>0.169355</td>\n",
       "      <td>0.166666</td>\n",
       "      <td>0.146715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.368856</td>\n",
       "      <td>-0.530640</td>\n",
       "      <td>-0.487672</td>\n",
       "      <td>-0.447722</td>\n",
       "      <td>-0.276366</td>\n",
       "      <td>-0.292531</td>\n",
       "      <td>-0.236326</td>\n",
       "      <td>-0.209993</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.546984</td>\n",
       "      <td>-0.427314</td>\n",
       "      <td>-0.527221</td>\n",
       "      <td>-0.588838</td>\n",
       "      <td>-0.624649</td>\n",
       "      <td>-0.577075</td>\n",
       "      <td>-0.652600</td>\n",
       "      <td>-0.500391</td>\n",
       "      <td>-0.386848</td>\n",
       "      <td>-0.161838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>chf12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.074907</td>\n",
       "      <td>0.105856</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>-0.439990</td>\n",
       "      <td>-0.876207</td>\n",
       "      <td>-1.187291</td>\n",
       "      <td>-1.334461</td>\n",
       "      <td>-1.255440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027454</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.025988</td>\n",
       "      <td>0.018896</td>\n",
       "      <td>0.033075</td>\n",
       "      <td>0.050003</td>\n",
       "      <td>0.059558</td>\n",
       "      <td>0.056467</td>\n",
       "      <td>0.098536</td>\n",
       "      <td>0.089279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>chf08</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.320028</td>\n",
       "      <td>-0.404340</td>\n",
       "      <td>-0.396922</td>\n",
       "      <td>-0.409747</td>\n",
       "      <td>-0.408599</td>\n",
       "      <td>-0.397462</td>\n",
       "      <td>-0.391675</td>\n",
       "      <td>-0.345731</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235219</td>\n",
       "      <td>-0.209356</td>\n",
       "      <td>-0.203681</td>\n",
       "      <td>-0.195236</td>\n",
       "      <td>-0.203310</td>\n",
       "      <td>-0.192466</td>\n",
       "      <td>-0.200470</td>\n",
       "      <td>-0.177530</td>\n",
       "      <td>-0.195617</td>\n",
       "      <td>-0.168229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>chf08</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.117367</td>\n",
       "      <td>-0.069165</td>\n",
       "      <td>-0.072747</td>\n",
       "      <td>-0.090340</td>\n",
       "      <td>-0.095915</td>\n",
       "      <td>-0.094605</td>\n",
       "      <td>-0.138618</td>\n",
       "      <td>-0.139901</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194281</td>\n",
       "      <td>-0.188166</td>\n",
       "      <td>-0.179020</td>\n",
       "      <td>-0.201753</td>\n",
       "      <td>-0.184603</td>\n",
       "      <td>-0.185422</td>\n",
       "      <td>-0.180237</td>\n",
       "      <td>-0.187840</td>\n",
       "      <td>-0.172069</td>\n",
       "      <td>-0.171569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>chf09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.191584</td>\n",
       "      <td>0.405085</td>\n",
       "      <td>0.315481</td>\n",
       "      <td>0.218790</td>\n",
       "      <td>-0.024663</td>\n",
       "      <td>-0.169857</td>\n",
       "      <td>-0.366068</td>\n",
       "      <td>-0.493332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.203226</td>\n",
       "      <td>-0.223304</td>\n",
       "      <td>-0.226758</td>\n",
       "      <td>-0.238972</td>\n",
       "      <td>-0.218572</td>\n",
       "      <td>-0.261438</td>\n",
       "      <td>-0.243642</td>\n",
       "      <td>-0.320345</td>\n",
       "      <td>-0.296373</td>\n",
       "      <td>-0.381885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>chf09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.118752</td>\n",
       "      <td>0.392734</td>\n",
       "      <td>0.244206</td>\n",
       "      <td>0.208688</td>\n",
       "      <td>0.097630</td>\n",
       "      <td>-0.171194</td>\n",
       "      <td>-0.322495</td>\n",
       "      <td>-0.314085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.229654</td>\n",
       "      <td>-0.227367</td>\n",
       "      <td>-0.237788</td>\n",
       "      <td>-0.277769</td>\n",
       "      <td>-0.221940</td>\n",
       "      <td>-0.239414</td>\n",
       "      <td>-0.211494</td>\n",
       "      <td>-0.217100</td>\n",
       "      <td>-0.271023</td>\n",
       "      <td>-0.403293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 65538 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1         2         3         4         5         6         7  \\\n",
       "0      213  1 -0.060085  0.001638 -0.014941 -0.018776 -0.110048 -0.160348   \n",
       "1      213  1 -0.467585 -0.650931 -0.595663 -0.627657 -0.552164 -0.532318   \n",
       "2      207  1 -0.155555 -0.229827 -0.207653 -0.210114 -0.191253 -0.184057   \n",
       "3      207  1  0.099644  0.098019  0.089555  0.108130  0.070369  0.083866   \n",
       "4      212  1 -0.368856 -0.530640 -0.487672 -0.447722 -0.276366 -0.292531   \n",
       "..     ... ..       ...       ...       ...       ...       ...       ...   \n",
       "157  chf12  2  0.074907  0.105856 -0.000567 -0.439990 -0.876207 -1.187291   \n",
       "158  chf08  2 -0.320028 -0.404340 -0.396922 -0.409747 -0.408599 -0.397462   \n",
       "159  chf08  2 -0.117367 -0.069165 -0.072747 -0.090340 -0.095915 -0.094605   \n",
       "160  chf09  2  0.191584  0.405085  0.315481  0.218790 -0.024663 -0.169857   \n",
       "161  chf09  2  0.118752  0.392734  0.244206  0.208688  0.097630 -0.171194   \n",
       "\n",
       "            8         9  ...     65528     65529     65530     65531  \\\n",
       "0   -0.196445 -0.287140  ... -0.145316 -0.088612  0.001568  0.066026   \n",
       "1   -0.500500 -0.486974  ...  0.273010  0.279927  0.213876  0.137012   \n",
       "2   -0.152477 -0.171106  ... -1.238173 -1.112138 -0.812259 -0.595419   \n",
       "3    0.073525  0.061310  ... -0.291689 -0.111845  0.180895  0.373213   \n",
       "4   -0.236326 -0.209993  ... -0.546984 -0.427314 -0.527221 -0.588838   \n",
       "..        ...       ...  ...       ...       ...       ...       ...   \n",
       "157 -1.334461 -1.255440  ... -0.027454  0.002023  0.025988  0.018896   \n",
       "158 -0.391675 -0.345731  ... -0.235219 -0.209356 -0.203681 -0.195236   \n",
       "159 -0.138618 -0.139901  ... -0.194281 -0.188166 -0.179020 -0.201753   \n",
       "160 -0.366068 -0.493332  ... -0.203226 -0.223304 -0.226758 -0.238972   \n",
       "161 -0.322495 -0.314085  ... -0.229654 -0.227367 -0.237788 -0.277769   \n",
       "\n",
       "        65532     65533     65534     65535     65536     65537  \n",
       "0    0.154291  0.214976  0.227396  0.172451  0.011588 -0.154281  \n",
       "1    0.019218 -0.031818 -0.068809 -0.068333 -0.178109 -0.136239  \n",
       "2   -0.444057 -0.326833 -0.117486 -0.038309 -0.015658  0.004507  \n",
       "3    0.486517  0.394578  0.283331  0.169355  0.166666  0.146715  \n",
       "4   -0.624649 -0.577075 -0.652600 -0.500391 -0.386848 -0.161838  \n",
       "..        ...       ...       ...       ...       ...       ...  \n",
       "157  0.033075  0.050003  0.059558  0.056467  0.098536  0.089279  \n",
       "158 -0.203310 -0.192466 -0.200470 -0.177530 -0.195617 -0.168229  \n",
       "159 -0.184603 -0.185422 -0.180237 -0.187840 -0.172069 -0.171569  \n",
       "160 -0.218572 -0.261438 -0.243642 -0.320345 -0.296373 -0.381885  \n",
       "161 -0.221940 -0.239414 -0.211494 -0.217100 -0.271023 -0.403293  \n",
       "\n",
       "[162 rows x 65538 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ECG-laurent.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "wxVtGDtuOAk1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/_09rqyyj0v3g_c9sgq8sp4k40000gn/T/ipykernel_1950/3767728652.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"1\" : \"y\"}, inplace=True)\n",
      "/var/folders/_t/_09rqyyj0v3g_c9sgq8sp4k40000gn/T/ipykernel_1950/3767728652.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['X'] = None\n"
     ]
    }
   ],
   "source": [
    "datas = df.iloc[:, 2:]\n",
    "datas = pd.DataFrame(datas).to_numpy()\n",
    "df = df.iloc[:, 1:2]\n",
    "\n",
    "df.rename(columns={\"1\" : \"y\"}, inplace=True)\n",
    "df['X'] = None\n",
    "\n",
    "feature_list = []\n",
    "for data in datas :\n",
    "    feature_list.append(get_features(data))\n",
    "    \n",
    "X_feature = pd.DataFrame(feature_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_feature\n",
    "y = df['y']\n",
    "\n",
    "# Take a small subset (10% of the full data)\n",
    "X_small, _, y_small, _ = train_test_split(X, y, train_size=0.1, random_state=42)\n",
    "\n",
    "# Now split this smaller subset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_small, y_small, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9VZ5cb6SQIlF"
   },
   "source": [
    "Now you have a first pipeline, do the same on the full dataset\n",
    "Report the train and test loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ydigZirQPT3"
   },
   "source": [
    "try to tweak the model hyperparameter to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cMeMnNXTQVVp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss (Log Loss): 0.0855\n",
      "Test Loss (Log Loss): 0.2431\n",
      "Train Accuracy: 1.00\n",
      "Test Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_proba = clf.predict_proba(X_train)\n",
    "y_test_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "train_loss = log_loss(y_train, y_train_pred_proba)\n",
    "test_loss = log_loss(y_test, y_test_pred_proba)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Train Loss (Log Loss): {train_loss:.4f}\")\n",
    "print(f\"Test Loss (Log Loss): {test_loss:.4f}\")\n",
    "print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KDBZQIyRki5"
   },
   "source": [
    "## Fourier transform features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrSJhsOeQWne"
   },
   "source": [
    "We want now to see if a model using only fourier transform could work.\n",
    "\n",
    "create a function get_fourier_coefficients(ecg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "S-dIwyPbQhTV"
   },
   "outputs": [],
   "source": [
    "def get_fourier_coefficients(ecg, n_coefficients=20):\n",
    "    fft_result = np.fft.fft(ecg)\n",
    "    fft_result = fft_result[:n_coefficients]\n",
    "    real_part = fft_result.real\n",
    "    imag_part = fft_result.imag\n",
    "    features = np.concatenate([real_part, imag_part])\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDpN0NMHQhxL"
   },
   "source": [
    "Using this function create a dataframe df_fourrier containing the fourrier transform coefficients and the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "lgB1xBetQsI2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/_09rqyyj0v3g_c9sgq8sp4k40000gn/T/ipykernel_1950/586825887.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('ECG-laurent.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-17599.976889</td>\n",
       "      <td>-758.813702</td>\n",
       "      <td>-93.278558</td>\n",
       "      <td>-592.319401</td>\n",
       "      <td>-305.129117</td>\n",
       "      <td>-385.483756</td>\n",
       "      <td>-791.780539</td>\n",
       "      <td>-459.654824</td>\n",
       "      <td>-1258.509759</td>\n",
       "      <td>315.708424</td>\n",
       "      <td>...</td>\n",
       "      <td>259.019479</td>\n",
       "      <td>-802.993730</td>\n",
       "      <td>515.802733</td>\n",
       "      <td>631.752566</td>\n",
       "      <td>-48.499544</td>\n",
       "      <td>-86.816673</td>\n",
       "      <td>-92.374215</td>\n",
       "      <td>-121.427423</td>\n",
       "      <td>-89.337117</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-14484.396444</td>\n",
       "      <td>-1625.487534</td>\n",
       "      <td>-1115.147467</td>\n",
       "      <td>-592.487213</td>\n",
       "      <td>-554.254257</td>\n",
       "      <td>-285.183354</td>\n",
       "      <td>296.268696</td>\n",
       "      <td>-204.265852</td>\n",
       "      <td>-1635.338876</td>\n",
       "      <td>865.993022</td>\n",
       "      <td>...</td>\n",
       "      <td>712.090468</td>\n",
       "      <td>98.169533</td>\n",
       "      <td>743.834019</td>\n",
       "      <td>540.724815</td>\n",
       "      <td>371.019023</td>\n",
       "      <td>650.477304</td>\n",
       "      <td>659.724292</td>\n",
       "      <td>722.124494</td>\n",
       "      <td>315.183089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10683.818667</td>\n",
       "      <td>385.954517</td>\n",
       "      <td>-196.939828</td>\n",
       "      <td>-224.784712</td>\n",
       "      <td>-96.282300</td>\n",
       "      <td>-673.024888</td>\n",
       "      <td>-577.757255</td>\n",
       "      <td>-508.416037</td>\n",
       "      <td>67.634488</td>\n",
       "      <td>-900.547863</td>\n",
       "      <td>...</td>\n",
       "      <td>452.045771</td>\n",
       "      <td>-602.824902</td>\n",
       "      <td>-80.833608</td>\n",
       "      <td>380.011376</td>\n",
       "      <td>31.910868</td>\n",
       "      <td>132.016497</td>\n",
       "      <td>-271.253223</td>\n",
       "      <td>-149.300160</td>\n",
       "      <td>224.742667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3536.462222</td>\n",
       "      <td>-264.551162</td>\n",
       "      <td>-298.594840</td>\n",
       "      <td>446.614788</td>\n",
       "      <td>-613.430463</td>\n",
       "      <td>-244.125989</td>\n",
       "      <td>-561.247176</td>\n",
       "      <td>402.691658</td>\n",
       "      <td>-785.782374</td>\n",
       "      <td>-201.149215</td>\n",
       "      <td>...</td>\n",
       "      <td>-812.093241</td>\n",
       "      <td>44.523408</td>\n",
       "      <td>-89.576617</td>\n",
       "      <td>-210.782327</td>\n",
       "      <td>45.826319</td>\n",
       "      <td>-236.954452</td>\n",
       "      <td>-416.225300</td>\n",
       "      <td>-184.073844</td>\n",
       "      <td>-222.929991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9756.496000</td>\n",
       "      <td>7.358478</td>\n",
       "      <td>464.681459</td>\n",
       "      <td>-467.787635</td>\n",
       "      <td>271.644373</td>\n",
       "      <td>98.127012</td>\n",
       "      <td>95.593713</td>\n",
       "      <td>-66.534328</td>\n",
       "      <td>865.344309</td>\n",
       "      <td>-182.809107</td>\n",
       "      <td>...</td>\n",
       "      <td>92.142159</td>\n",
       "      <td>289.296922</td>\n",
       "      <td>-233.400921</td>\n",
       "      <td>-157.681651</td>\n",
       "      <td>81.472825</td>\n",
       "      <td>573.779937</td>\n",
       "      <td>-92.572111</td>\n",
       "      <td>-150.177272</td>\n",
       "      <td>-193.495854</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0            1            2           3           4           5  \\\n",
       "0 -17599.976889  -758.813702   -93.278558 -592.319401 -305.129117 -385.483756   \n",
       "1 -14484.396444 -1625.487534 -1115.147467 -592.487213 -554.254257 -285.183354   \n",
       "2 -10683.818667   385.954517  -196.939828 -224.784712  -96.282300 -673.024888   \n",
       "3   3536.462222  -264.551162  -298.594840  446.614788 -613.430463 -244.125989   \n",
       "4  -9756.496000     7.358478   464.681459 -467.787635  271.644373   98.127012   \n",
       "\n",
       "            6           7            8           9  ...          31  \\\n",
       "0 -791.780539 -459.654824 -1258.509759  315.708424  ...  259.019479   \n",
       "1  296.268696 -204.265852 -1635.338876  865.993022  ...  712.090468   \n",
       "2 -577.757255 -508.416037    67.634488 -900.547863  ...  452.045771   \n",
       "3 -561.247176  402.691658  -785.782374 -201.149215  ... -812.093241   \n",
       "4   95.593713  -66.534328   865.344309 -182.809107  ...   92.142159   \n",
       "\n",
       "           32          33          34          35          36          37  \\\n",
       "0 -802.993730  515.802733  631.752566  -48.499544  -86.816673  -92.374215   \n",
       "1   98.169533  743.834019  540.724815  371.019023  650.477304  659.724292   \n",
       "2 -602.824902  -80.833608  380.011376   31.910868  132.016497 -271.253223   \n",
       "3   44.523408  -89.576617 -210.782327   45.826319 -236.954452 -416.225300   \n",
       "4  289.296922 -233.400921 -157.681651   81.472825  573.779937  -92.572111   \n",
       "\n",
       "           38          39  label  \n",
       "0 -121.427423  -89.337117      1  \n",
       "1  722.124494  315.183089      1  \n",
       "2 -149.300160  224.742667      1  \n",
       "3 -184.073844 -222.929991      1  \n",
       "4 -150.177272 -193.495854      1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ECG-laurent.csv')\n",
    "\n",
    "datas = df.iloc[:, 2:].to_numpy()\n",
    "labels = df.iloc[:, 1]\n",
    "\n",
    "fourier_features = [get_fourier_coefficients(ecg, n_coefficients=20) for ecg in datas]\n",
    "\n",
    "df_fourier = pd.DataFrame(fourier_features)\n",
    "df_fourier['label'] = labels.values\n",
    "\n",
    "df_fourier.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvazWtOTQsjN"
   },
   "source": [
    "Try to train a model using the Fourrier coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Fourier Coef: 0.79\n"
     ]
    }
   ],
   "source": [
    "X = df_fourier.drop(columns=['label'])\n",
    "y = df_fourier['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy Fourier Coef: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdQJVPwTQyPW"
   },
   "source": [
    "Try to learn a model using both fourrier coefficient and the features from the previous sections. Does it work ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "L_btzUlQQxf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Combined Features: 0.85\n"
     ]
    }
   ],
   "source": [
    "combined_features = pd.concat([X_feature, df_fourier.drop(columns=['label'])], axis=1)\n",
    "\n",
    "y_combined = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy Combined Features: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdMV9alsRYA7"
   },
   "source": [
    "## Wavelets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now wants to use another signal decomposition which are called wavelet. Wavelet are a multi-scale function decomposition on a familly of functions generated from what is called a mother wavelet.\n",
    "\n",
    "Using PyWavelet make a function get_wavelet_coefficients(ecg) that returns the wavelet coefficient of a given ECG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XW8x9kHJOAk2"
   },
   "outputs": [],
   "source": [
    "def get_wavelet_coefficients(ecg, wavelet='db4', level=4):\n",
    "    coeffs = pywt.wavedec(ecg, wavelet=wavelet, level=level)\n",
    "    wavelet_features = np.hstack(coeffs)\n",
    "    return wavelet_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTCCNTinOAk3"
   },
   "source": [
    "Using the get_wavelet_coefficients, create a dataframe when the features are the coefficients and include the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/_09rqyyj0v3g_c9sgq8sp4k40000gn/T/ipykernel_1950/4209439223.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('ECG-laurent.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65553</th>\n",
       "      <th>65554</th>\n",
       "      <th>65555</th>\n",
       "      <th>65556</th>\n",
       "      <th>65557</th>\n",
       "      <th>65558</th>\n",
       "      <th>65559</th>\n",
       "      <th>65560</th>\n",
       "      <th>65561</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.228740</td>\n",
       "      <td>-0.190008</td>\n",
       "      <td>-0.179619</td>\n",
       "      <td>-0.226580</td>\n",
       "      <td>-0.031340</td>\n",
       "      <td>-1.018605</td>\n",
       "      <td>-0.444753</td>\n",
       "      <td>-2.368966</td>\n",
       "      <td>-1.634749</td>\n",
       "      <td>-0.977731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020990</td>\n",
       "      <td>-0.037387</td>\n",
       "      <td>0.028253</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>-0.028554</td>\n",
       "      <td>0.014615</td>\n",
       "      <td>0.031316</td>\n",
       "      <td>-0.027797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.284291</td>\n",
       "      <td>-2.311781</td>\n",
       "      <td>-2.299607</td>\n",
       "      <td>-2.283637</td>\n",
       "      <td>-2.467491</td>\n",
       "      <td>-1.493960</td>\n",
       "      <td>-3.442873</td>\n",
       "      <td>-4.733150</td>\n",
       "      <td>-1.800736</td>\n",
       "      <td>-0.455900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016427</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>-0.018340</td>\n",
       "      <td>-0.019976</td>\n",
       "      <td>0.006214</td>\n",
       "      <td>-0.063029</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.055184</td>\n",
       "      <td>-0.012997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.821863</td>\n",
       "      <td>-0.796012</td>\n",
       "      <td>-0.774485</td>\n",
       "      <td>-0.775475</td>\n",
       "      <td>-0.978186</td>\n",
       "      <td>-0.179384</td>\n",
       "      <td>-0.315090</td>\n",
       "      <td>-1.138809</td>\n",
       "      <td>-0.368271</td>\n",
       "      <td>0.456424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109406</td>\n",
       "      <td>0.154508</td>\n",
       "      <td>0.025962</td>\n",
       "      <td>-0.032860</td>\n",
       "      <td>0.056736</td>\n",
       "      <td>-0.031413</td>\n",
       "      <td>0.009088</td>\n",
       "      <td>0.012298</td>\n",
       "      <td>-0.058915</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.348926</td>\n",
       "      <td>0.375198</td>\n",
       "      <td>0.371578</td>\n",
       "      <td>0.332356</td>\n",
       "      <td>0.535287</td>\n",
       "      <td>-0.082380</td>\n",
       "      <td>2.922918</td>\n",
       "      <td>0.238627</td>\n",
       "      <td>0.597085</td>\n",
       "      <td>1.542039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037289</td>\n",
       "      <td>0.045591</td>\n",
       "      <td>0.031034</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.045184</td>\n",
       "      <td>-0.008458</td>\n",
       "      <td>-0.029453</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.643063</td>\n",
       "      <td>-1.666765</td>\n",
       "      <td>-1.676780</td>\n",
       "      <td>-1.630421</td>\n",
       "      <td>-1.849698</td>\n",
       "      <td>-0.928686</td>\n",
       "      <td>0.243894</td>\n",
       "      <td>-1.045281</td>\n",
       "      <td>-0.736337</td>\n",
       "      <td>-0.233167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263982</td>\n",
       "      <td>-0.425948</td>\n",
       "      <td>0.128538</td>\n",
       "      <td>-0.049629</td>\n",
       "      <td>-0.076230</td>\n",
       "      <td>-0.007552</td>\n",
       "      <td>-0.001764</td>\n",
       "      <td>0.022396</td>\n",
       "      <td>0.089177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-1.256411</td>\n",
       "      <td>-1.176086</td>\n",
       "      <td>-1.000601</td>\n",
       "      <td>-1.271352</td>\n",
       "      <td>-0.768256</td>\n",
       "      <td>-2.578013</td>\n",
       "      <td>0.597282</td>\n",
       "      <td>0.373866</td>\n",
       "      <td>0.595444</td>\n",
       "      <td>-1.932390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>-0.010335</td>\n",
       "      <td>0.009463</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.022055</td>\n",
       "      <td>-0.007558</td>\n",
       "      <td>-0.020769</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>-1.547153</td>\n",
       "      <td>-1.558670</td>\n",
       "      <td>-1.539930</td>\n",
       "      <td>-1.546184</td>\n",
       "      <td>-1.587573</td>\n",
       "      <td>-1.424208</td>\n",
       "      <td>-1.299591</td>\n",
       "      <td>-1.291218</td>\n",
       "      <td>-1.166278</td>\n",
       "      <td>-1.821944</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007847</td>\n",
       "      <td>-0.012782</td>\n",
       "      <td>-0.000983</td>\n",
       "      <td>-0.008603</td>\n",
       "      <td>-0.008715</td>\n",
       "      <td>-0.017159</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.017860</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-0.365921</td>\n",
       "      <td>-0.357162</td>\n",
       "      <td>-0.362281</td>\n",
       "      <td>-0.369334</td>\n",
       "      <td>-0.313935</td>\n",
       "      <td>-0.525250</td>\n",
       "      <td>-0.576419</td>\n",
       "      <td>-0.590355</td>\n",
       "      <td>-0.647901</td>\n",
       "      <td>-0.987933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.011216</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.008229</td>\n",
       "      <td>-0.002588</td>\n",
       "      <td>-0.008707</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.731175</td>\n",
       "      <td>0.785912</td>\n",
       "      <td>0.819470</td>\n",
       "      <td>0.593377</td>\n",
       "      <td>1.540172</td>\n",
       "      <td>-1.551643</td>\n",
       "      <td>-0.743050</td>\n",
       "      <td>-3.033243</td>\n",
       "      <td>-1.141369</td>\n",
       "      <td>-0.903578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016191</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.021204</td>\n",
       "      <td>0.028493</td>\n",
       "      <td>0.039656</td>\n",
       "      <td>-0.012011</td>\n",
       "      <td>-0.042655</td>\n",
       "      <td>-0.025372</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.690330</td>\n",
       "      <td>0.747722</td>\n",
       "      <td>0.748915</td>\n",
       "      <td>0.634233</td>\n",
       "      <td>1.083086</td>\n",
       "      <td>-0.216203</td>\n",
       "      <td>-2.680500</td>\n",
       "      <td>-1.776808</td>\n",
       "      <td>-0.004091</td>\n",
       "      <td>0.030515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.038516</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>-0.000744</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>-0.027506</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 65563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.228740 -0.190008 -0.179619 -0.226580 -0.031340 -1.018605 -0.444753   \n",
       "1   -2.284291 -2.311781 -2.299607 -2.283637 -2.467491 -1.493960 -3.442873   \n",
       "2   -0.821863 -0.796012 -0.774485 -0.775475 -0.978186 -0.179384 -0.315090   \n",
       "3    0.348926  0.375198  0.371578  0.332356  0.535287 -0.082380  2.922918   \n",
       "4   -1.643063 -1.666765 -1.676780 -1.630421 -1.849698 -0.928686  0.243894   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "157 -1.256411 -1.176086 -1.000601 -1.271352 -0.768256 -2.578013  0.597282   \n",
       "158 -1.547153 -1.558670 -1.539930 -1.546184 -1.587573 -1.424208 -1.299591   \n",
       "159 -0.365921 -0.357162 -0.362281 -0.369334 -0.313935 -0.525250 -0.576419   \n",
       "160  0.731175  0.785912  0.819470  0.593377  1.540172 -1.551643 -0.743050   \n",
       "161  0.690330  0.747722  0.748915  0.634233  1.083086 -0.216203 -2.680500   \n",
       "\n",
       "            7         8         9  ...     65553     65554     65555  \\\n",
       "0   -2.368966 -1.634749 -0.977731  ...  0.020990 -0.037387  0.028253   \n",
       "1   -4.733150 -1.800736 -0.455900  ...  0.016427  0.000257 -0.018340   \n",
       "2   -1.138809 -0.368271  0.456424  ... -0.109406  0.154508  0.025962   \n",
       "3    0.238627  0.597085  1.542039  ...  0.037289  0.045591  0.031034   \n",
       "4   -1.045281 -0.736337 -0.233167  ...  0.263982 -0.425948  0.128538   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "157  0.373866  0.595444 -1.932390  ...  0.007585 -0.010335  0.009463   \n",
       "158 -1.291218 -1.166278 -1.821944  ...  0.007847 -0.012782 -0.000983   \n",
       "159 -0.590355 -0.647901 -0.987933  ...  0.000326  0.000340  0.011216   \n",
       "160 -3.033243 -1.141369 -0.903578  ...  0.016191  0.002240  0.005429   \n",
       "161 -1.776808 -0.004091  0.030515  ...  0.000801  0.009888  0.001010   \n",
       "\n",
       "        65556     65557     65558     65559     65560     65561  label  \n",
       "0    0.002237 -0.000266 -0.028554  0.014615  0.031316 -0.027797      1  \n",
       "1   -0.019976  0.006214 -0.063029  0.020517  0.055184 -0.012997      1  \n",
       "2   -0.032860  0.056736 -0.031413  0.009088  0.012298 -0.058915      1  \n",
       "3    0.009156 -0.016872  0.045184 -0.008458 -0.029453  0.015599      1  \n",
       "4   -0.049629 -0.076230 -0.007552 -0.001764  0.022396  0.089177      1  \n",
       "..        ...       ...       ...       ...       ...       ...    ...  \n",
       "157  0.001435  0.001654  0.022055 -0.007558 -0.020769  0.006174      2  \n",
       "158 -0.008603 -0.008715 -0.017159  0.005511  0.017860  0.006525      2  \n",
       "159  0.009061  0.001568  0.008229 -0.002588 -0.008707 -0.001065      2  \n",
       "160  0.021204  0.028493  0.039656 -0.012011 -0.042655 -0.025372      2  \n",
       "161  0.038516  0.006706  0.002083 -0.000744  0.001390 -0.027506      2  \n",
       "\n",
       "[162 rows x 65563 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ECG-laurent.csv')\n",
    "\n",
    "datas = df.iloc[:, 2:].to_numpy()\n",
    "labels = df.iloc[:, 1]\n",
    "\n",
    "wavelet_features = [get_wavelet_coefficients(ecg, wavelet='db4', level=4) for ecg in datas]\n",
    "\n",
    "df_wavelet = pd.DataFrame(wavelet_features)\n",
    "\n",
    "df_wavelet['label'] = labels.values\n",
    "df_wavelet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oHiL5a-ROgR"
   },
   "source": [
    "Train a random forest classifier with such features. DOes the model work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "LTXayPGBOAk4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Wavelet Features: 0.64\n"
     ]
    }
   ],
   "source": [
    "X_wavelet = df_wavelet.drop(columns=['label'])\n",
    "y_wavelet = df_wavelet['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_wavelet, y_wavelet, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy Wavelet Features: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOBmMfHtZHyK"
   },
   "source": [
    "Add one or several of the previous feature functions and try to train another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "Jv2JOjKqZG45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Wavelet, Fourier, Statistical: 0.61\n"
     ]
    }
   ],
   "source": [
    "df_fourier_combined = pd.DataFrame(fourier_features)\n",
    "\n",
    "X_combined = pd.concat([X_feature, df_fourier_combined, df_wavelet.drop(columns=['label'])], axis=1)\n",
    "y_combined = y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy using Wavelet, Fourier, Statistical: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ox_RU4iVZRw6"
   },
   "source": [
    "Specify the methodology you used to train the model and report the various attempts results into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/_09rqyyj0v3g_c9sgq8sp4k40000gn/T/ipykernel_1950/739754870.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('ECG-laurent.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wavelet only</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fourier only</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Statistical only</td>\n",
       "      <td>0.878788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wavelet + Fourier</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wavelet + Statistical</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wavelet + Fourier + Statistical</td>\n",
       "      <td>0.606061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Experiment  Accuracy\n",
       "0                     Wavelet only  0.636364\n",
       "1                     Fourier only  0.787879\n",
       "2                 Statistical only  0.878788\n",
       "3                Wavelet + Fourier  0.575758\n",
       "4            Wavelet + Statistical  0.575758\n",
       "5  Wavelet + Fourier + Statistical  0.606061"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ECG-laurent.csv')\n",
    "\n",
    "datas = df.iloc[:, 2:].to_numpy()\n",
    "y = df.iloc[:, 1]\n",
    "\n",
    "def train_and_evaluate(X_features, y_labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size=0.2, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "X_wavelet = df_wavelet.drop(columns=['label'])\n",
    "y_wavelet = y\n",
    "accuracy_wavelet = train_and_evaluate(X_wavelet, y_wavelet)\n",
    "\n",
    "X_fourier = df_fourier_combined\n",
    "y_fourier = y\n",
    "accuracy_fourier = train_and_evaluate(X_fourier, y_fourier)\n",
    "\n",
    "X_statistical = X_feature\n",
    "y_statistical = y\n",
    "accuracy_statistical = train_and_evaluate(X_statistical, y_statistical)\n",
    "\n",
    "X_combined_fourier_wavelet = pd.concat([df_wavelet.drop(columns=['label']), df_fourier_combined], axis=1)\n",
    "accuracy_combined_fourier_wavelet = train_and_evaluate(X_combined_fourier_wavelet, y_combined)\n",
    "\n",
    "X_combined_wavelet_statistical = pd.concat([df_wavelet.drop(columns=['label']), X_feature], axis=1)\n",
    "accuracy_combined_wavelet_statistical = train_and_evaluate(X_combined_wavelet_statistical, y_combined)\n",
    "\n",
    "X_combined = pd.concat([X_feature, df_fourier_combined, df_wavelet.drop(columns=['label'])], axis=1)\n",
    "accuracy_combined_all = train_and_evaluate(X_combined, y_combined)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Experiment': [\n",
    "        'Wavelet only',\n",
    "        'Fourier only',\n",
    "        'Statistical only',\n",
    "        'Wavelet + Fourier',\n",
    "        'Wavelet + Statistical',\n",
    "        'Wavelet + Fourier + Statistical'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_wavelet,\n",
    "        accuracy_fourier,\n",
    "        accuracy_statistical,\n",
    "        accuracy_combined_fourier_wavelet,\n",
    "        accuracy_combined_wavelet_statistical,\n",
    "        accuracy_combined_all\n",
    "    ]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AL5aD-ckRnbw"
   },
   "source": [
    "## Deep learning (1D CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo0FE1soOAk4"
   },
   "source": [
    "Now we want to see if we can skip all theses feature engineering techniques !\n",
    "Design and train a multi-layer one dimensional CNN using the raw ECG signal as features.\n",
    "\n",
    "\n",
    "Could you reach or surpass the feature based models ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R55iLcpBRNF_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/_09rqyyj0v3g_c9sgq8sp4k40000gn/T/ipykernel_1950/3448007457.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('ECG-laurent.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ECG-laurent.csv')\n",
    "\n",
    "X = df.iloc[:, 2:].to_numpy()\n",
    "y = df.iloc[:, 1].to_numpy()\n",
    "\n",
    "X = X[..., np.newaxis]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.reshape(-1, X.shape[-1])).reshape(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    model.add(layers.Conv1D(16, 3, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    \n",
    "    model.add(layers.Conv1D(32, 3, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    \n",
    "    model.add(layers.Dense(len(np.unique(y)), activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - ETA: 0s - loss: 11.1595 - accuracy: 0.4651WARNING:tensorflow:5 out of the last 40 calls to <function Model.make_test_function.<locals>.test_function at 0x15497d7e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "9/9 [==============================] - 6s 542ms/step - loss: 11.1595 - accuracy: 0.4651 - val_loss: 4.9303 - val_accuracy: 0.5758\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 5s 498ms/step - loss: 1.5759 - accuracy: 0.7829 - val_loss: 1.0655 - val_accuracy: 0.6364\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 5s 497ms/step - loss: 0.4270 - accuracy: 0.8527 - val_loss: 0.5572 - val_accuracy: 0.7879\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 5s 506ms/step - loss: 0.2816 - accuracy: 0.9302 - val_loss: 1.2917 - val_accuracy: 0.7273\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 5s 502ms/step - loss: 0.1429 - accuracy: 0.9535 - val_loss: 0.9137 - val_accuracy: 0.7879\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 5s 498ms/step - loss: 0.0482 - accuracy: 0.9922 - val_loss: 0.8319 - val_accuracy: 0.7576\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 5s 502ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.7879\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 5s 504ms/step - loss: 0.0302 - accuracy: 0.9845 - val_loss: 1.0149 - val_accuracy: 0.7879\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 5s 511ms/step - loss: 0.0296 - accuracy: 0.9845 - val_loss: 0.9307 - val_accuracy: 0.7879\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 5s 509ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.8170 - val_accuracy: 0.7879\n"
     ]
    }
   ],
   "source": [
    "model = create_cnn_model(X_train.shape[1:])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step - loss: 0.8170 - accuracy: 0.7879\n",
      "Test Accuracy: 0.79\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
